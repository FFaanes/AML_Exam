{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28773ce3-a190-44e7-9de9-fdc422e4d3b9",
   "metadata": {},
   "source": [
    "# AML Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404afa46-4f92-4696-a04d-c1b4a0d941da",
   "metadata": {},
   "source": [
    "•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9ffbe-5ef2-48be-b49b-1e5769c8f32d",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78de19-ae1c-4748-99bc-1a1ef3fa5f07",
   "metadata": {},
   "source": [
    "• Downloading external libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f46be4-ec44-42b6-ba89-420c0fd1a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99189030-ecfa-4aa0-a8fe-141fabadaa17",
   "metadata": {
    "tags": []
   },
   "source": [
    "• Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57210b3-ccf2-4810-9eb7-bd4417817e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e85be72-8376-4f19-8965-58b79b7e2cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_unwanted_folders(folder):\n",
    "    if \".DS_Store\" in folder:\n",
    "        folder.remove(\".DS_Store\")\n",
    "        print(\"Removed DS_Store\")\n",
    "    if \".ipynb_checkpoints\" in folder:\n",
    "        folder.remove(\".ipynb_checkpoints\")\n",
    "        print(\"removed checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b867ed-bfb9-4a12-9757-011e4febfa09",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 2. Preparing and Augmenting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7a42c-4eff-48dc-86cc-7ff526d1a3fa",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.1 Augmenting Data to get more samples.\n",
    "    • Flip Horizontal\n",
    "    • Flip Vertical\n",
    "    • Brightness\n",
    "    • Contrast\n",
    "    • Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37ecdd-6f94-44c5-be71-401649591100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all disease folders in data\n",
    "original_data_path = \"./Data/original_data/\"\n",
    "original_data_folder = os.listdir(original_data_path)\n",
    "remove_unwanted_folders(original_data_folder)\n",
    "\n",
    "\n",
    "augmented_data_path = \"./Data/aug_data/\"\n",
    "augmented_data_folder = os.listdir(augmented_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92e19d6-e84b-4dd0-b8d6-30247706e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_Augmented_Image(save_path,img):\n",
    "    cv2.imwrite(save_path,img)\n",
    "\n",
    "for disease in original_data_folder: # Looping over all disease folders\n",
    "    \n",
    "    # Get all images inside of current disease folder\n",
    "    images = os.listdir(os.path.join(original_data_path,disease))\n",
    "\n",
    "    # Loading each image in folder\n",
    "    for current_image in images:\n",
    "        # Get full path of current image\n",
    "        current_image_full_path = os.path.join(original_data_path, disease, current_image)\n",
    "        \n",
    "        #Save Original Image\n",
    "        current_image_cv2 = cv2.imread(current_image_full_path)                                \n",
    "        save_Augmented_Image(os.path.join(augmented_data_path, disease, \"o_\"+current_image),current_image_cv2)\n",
    "        \n",
    "        # Flip Horizontal\n",
    "        horizontal_flip_image = cv2.flip(current_image_cv2,1)\n",
    "        save_Augmented_Image(os.path.join(augmented_data_path,disease,\"fH_\"+current_image),horizontal_flip_image)\n",
    "\n",
    "        # Flip Vertical\n",
    "        vertical_flip_image = cv2.flip(current_image_cv2,0)\n",
    "        save_Augmented_Image(os.path.join(augmented_data_path,disease,\"fV_\"+current_image),vertical_flip_image)\n",
    "\n",
    "        # Adjust Brightness\n",
    "        brightness_higher = cv2.convertScaleAbs(current_image_cv2, alpha=1, beta=70)\n",
    "        brightness_lower = cv2.convertScaleAbs(current_image_cv2, alpha=1, beta=-40)\n",
    "        save_Augmented_Image(os.path.join(augmented_data_path,disease,\"bH_\"+current_image),brightness_higher)\n",
    "        save_Augmented_Image(os.path.join(augmented_data_path,disease,\"bL_\"+current_image),brightness_lower)\n",
    "\n",
    "        # Adjust Contrast\n",
    "        contrast_higher = cv2.convertScaleAbs(current_image_cv2, alpha=1.6, beta=0)\n",
    "        contrast_lower = cv2.convertScaleAbs(current_image_cv2, alpha=0.7, beta=0)\n",
    "        save_Augmented_Image(os.path.join(augmented_data_path,disease,\"cH_\"+current_image),contrast_higher)\n",
    "        save_Augmented_Image(os.path.join(augmented_data_path,disease,\"cL_\"+current_image),contrast_lower)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95029b11-d7d7-4190-9c33-d6e01257c3c4",
   "metadata": {},
   "source": [
    "## 2.2 Saving augmented data into train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "162509c4-f3ed-4d95-856f-1860343990eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed checkpoints\n",
      "['FU-athlete-foot', 'VI-chickenpox', 'VI-shingles', 'FU-nail-fungus', 'BA-impetigo', 'PA-cutaneous-larva-migrans', 'FU-ringworm', 'BA- cellulitis']\n"
     ]
    }
   ],
   "source": [
    "# Get list of all disease folders in data\n",
    "original_data_path = \"./Data/aug_data/\"\n",
    "original_data_folder = os.listdir(original_data_path)\n",
    "\n",
    "remove_unwanted_folders(original_data_folder)\n",
    "print(original_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cdcd6fd-d3e2-4afd-8a43-354dcc03459d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for disease in original_data_folder:\n",
    "    # Get all images inside each corresponding disease folder\n",
    "    images = np.array(os.listdir(os.path.join(original_data_path,disease)))\n",
    "    \n",
    "    # Specify train, test and validation sizes\n",
    "    train_partition = int(len(images)*.7)\n",
    "    validation_partition = int(len(images)*.2)\n",
    "    test_partition = int(len(images)*.1)\n",
    "    \n",
    "    # Empty lists to store all numbers in range into a list.\n",
    "    train_partition_indexes = []\n",
    "    validation_partition_indexes = []\n",
    "    test_partition_indexes = []\n",
    "    \n",
    "    # Array of Train images from partition.\n",
    "    for x in range(0,train_partition):\n",
    "        train_partition_indexes.append(x)\n",
    "    train_image_array = np.take(images,train_partition_indexes)\n",
    "    \n",
    "    # Array of Validation images from partition.\n",
    "    for x in range(train_partition, train_partition + validation_partition):\n",
    "        validation_partition_indexes.append(x)\n",
    "    validation_image_array = np.take(images, validation_partition_indexes)\n",
    "    \n",
    "    # Array of Test images from partition.\n",
    "    for x in range(train_partition + validation_partition , train_partition + validation_partition + test_partition):\n",
    "        test_partition_indexes.append(x)\n",
    "    test_image_array = np.take(images, test_partition_indexes)\n",
    "        \n",
    "    \n",
    "    # Used for Generating disease folders in train, validation and test directories.\n",
    "    #os.mkdir(f\"./Data/data/train/{disease}\")\n",
    "    #os.mkdir(f\"./Data/data/test/{disease}\")\n",
    "    #os.mkdir(f\"./Data/data/val/{disease}\")\n",
    "    \n",
    "    # Defining path to new folders\n",
    "    train_folder_path = \"./Data/data/train/\"\n",
    "    validation_folder_path = \"./Data/data/val/\"\n",
    "    test_folder_path = \"./Data/data/test/\"\n",
    "    \n",
    "    # Moving images to their respective train, validation and test folders\n",
    "    # • Train Images\n",
    "    for current_image in train_image_array:\n",
    "        current_image_full_path = os.path.join(original_data_path, disease, current_image)\n",
    "        shutil.copyfile(current_image_full_path, os.path.join(train_folder_path, disease, current_image))\n",
    "\n",
    "    # • Validation Images\n",
    "    for current_image in validation_image_array:\n",
    "        current_image_full_path = os.path.join(original_data_path, disease, current_image)\n",
    "        shutil.copyfile(current_image_full_path, os.path.join(validation_folder_path, disease, current_image))\n",
    "    \n",
    "    # • Test Images\n",
    "    for current_image in test_image_array:\n",
    "        current_image_full_path = os.path.join(original_data_path, disease, current_image)\n",
    "        shutil.copyfile(current_image_full_path, os.path.join(test_folder_path, disease, current_image)) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6337a845-60aa-410e-b19d-2e3ef552fd2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4228a3-a97b-414f-a178-c80a26e3e29a",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 3.1 ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfbaed-09ee-42e5-b0c2-7b219be65cad",
   "metadata": {},
   "source": [
    "### • Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84055604-5aa8-4d15-8248-296a3f73ca31",
   "metadata": {},
   "source": [
    "### • Load processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e1ba3-44ac-4e13-b1a1-23e27a5452e2",
   "metadata": {},
   "source": [
    "### • Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce0e64-0a8b-44d8-8ff9-64d14f95bcc7",
   "metadata": {},
   "source": [
    "### • Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e9a61-4e43-4dd6-819d-6f16bb9ca1e0",
   "metadata": {},
   "source": [
    "### • Export model as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f273b0-b4f7-438a-b458-e766b8b18520",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 3.2 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c0987-979f-42a3-9a8e-7045ff6261b5",
   "metadata": {},
   "source": [
    "### • Defining Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e190763-ebd0-4177-a1fd-788e0fea49f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"./Data/data/train/\" # Augmented Data\n",
    "train_path = \"./Data/original_data/\" # Original Data\n",
    "train_folder = os.listdir(train_path)\n",
    "remove_unwanted_folders(train_folder)\n",
    "\n",
    "val_path = \"./Data/data/val/\" # Augmented Data\n",
    "val_path = \"./Data/original_data/\" # Original Data\n",
    "val_folder = os.listdir(val_path)\n",
    "remove_unwanted_folders(val_folder)\n",
    "\n",
    "test_path = \"./Data/data/test/\" # Augmented Data\n",
    "test_path = \"./Data/original_data/\" # Original Data\n",
    "test_folder = os.listdir(test_path)\n",
    "remove_unwanted_folders(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad1a915-9784-4de7-a27f-b604aa4fb247",
   "metadata": {},
   "source": [
    "### • Loading data with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d213ac-7634-4a8e-a16e-08b0942ca12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5670 files belonging to 8 classes.\n",
      "Found 1614 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train = tf.keras.utils.image_dataset_from_directory(\"./Data/data/train\",image_size=(224,224))\n",
    "val = tf.keras.utils.image_dataset_from_directory(\"./Data/data/val\", image_size=(224,224))\n",
    "#test = tf.keras.utils.image_dataset_from_directory(\"./Data/data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a604d89-9a28-4e95-b55d-8178453e5419",
   "metadata": {},
   "source": [
    "### • Transforming from regular 0-255 values to 0-1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "0a916750-cd95-41d8-aeb8-aec6009709b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = train.map(lambda x,y: (x/255, y))\n",
    "#val = val.map(lambda x,y: (x/255, y))\n",
    "#test = test.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "c197dd37-76b6-4ed5-a7a6-a35742e57387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_size = int(len(data)*.7)\n",
    "#val_size = int(len(data)*.2)\n",
    "#test_size = int(len(data)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "b11b588f-d3bb-4888-b23e-9491dd96f8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = data.take(train_size)\n",
    "#val = data.skip(train_size).take(val_size)\n",
    "#test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b789de4-59fa-4e68-840b-069117653a4b",
   "metadata": {},
   "source": [
    "### • Importing Tensorflow libraries for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4207d5a6-c2b3-4f02-a37b-e27373f45b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02630ac-caa7-49af-92c9-254fb15410ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041917b-b47d-4b66-9196-c74875f49ba6",
   "metadata": {},
   "source": [
    "### • Defining Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "c65eae6d-c3e7-4871-8e6f-67fc47794286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Github\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(224, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.add(Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "cc37da36-6178-4b68-9bc5-9affbb668baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "model.add(Conv2D(16, 3, 1,activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, 3, 1,activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, 3, 1,activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9b6817-313f-4c6b-b205-1772f1b32318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test\n",
    "model.add(Conv2D(128, (3,3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3,3),  activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3,3),  activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13ed2a-f1ce-4ee5-86e2-cb12a34d1c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62ee6d-3920-40eb-96d9-5efaee1bcdca",
   "metadata": {},
   "source": [
    "### • Compiling and training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59380e9e-ba7d-4d22-8b50-00ffe725f3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69c13f5-3740-43b6-a140-78845ed65f0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1b8c255-b9f1-45e6-94f6-e708f5d5cb2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ce423-a5a2-48ce-aa25-feeaa31eabdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc77bc-2f58-44b7-9ec9-2451230b711a",
   "metadata": {},
   "source": [
    "### • Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7c1f8-fa82-465a-93af-98d185f31881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1017e96-a539-48c5-a1e9-c0dea7df1280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903e5c1-1ddc-45c4-b6c6-e1cc1ee70ba0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### • Mapping Classes to indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "181241f5-d2b8-4ed6-a05b-b340177b504a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    0: 'BA- cellulitis',\n",
    "    1: 'BA-impetigo',\n",
    "    2: 'FU-athlete-foot',\n",
    "    3: 'FU-nail-fungus',\n",
    "    4: 'FU-ringworm',\n",
    "    5: 'PA-cutaneous-larva-migrans',\n",
    "    6: 'VI-chickenpox',\n",
    "    7: 'VI-shingles'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e8e9e-7ab7-46f5-8bb3-9ae898401bc0",
   "metadata": {},
   "source": [
    "### • Loading and resizing image for test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8b14c-3b70-44d8-9661-19724424c6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./Data/data/test/BA- cellulitis/bH_BA- cellulitis (66).jpg')\n",
    "resize = tf.image.resize(img, (224,224))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4998dce-c8cc-4dbd-9ba7-721af964e11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_image = resize/255\n",
    "\n",
    "yhat = model.predict(np.expand_dims(pred_image, 0))\n",
    "\n",
    "print(yhat)\n",
    "class_label = np.argmax(yhat)\n",
    "predicted_class = f\"{class_map[class_label]}\"\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f64828-72c5-4bfd-840b-03b7fe76edda",
   "metadata": {},
   "source": [
    "### • Export model as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c4d945b-febb-4d4b-9416-ba9cc32e60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(\"./Saved_Models\",\"CNN_V1.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e2ce9-9763-456e-b27a-073704cfdf20",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 3.3 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad12889-e854-4d10-b00c-576d6fd15457",
   "metadata": {},
   "source": [
    "### • Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c499cd85-fcbe-463a-b35c-418a1616c3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d90218-625f-4bb8-aade-efdb514272cc",
   "metadata": {},
   "source": [
    "### • Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c574d4c0-6b39-4831-b3e3-073288b89aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"./Data/data/train/\" # Augmented Data\n",
    "train_folder = os.listdir(train_path)\n",
    "remove_unwanted_folders(train_folder)\n",
    "\n",
    "val_path = \"./Data/data/val/\" # Augmented Data\n",
    "val_folder = os.listdir(val_path)\n",
    "remove_unwanted_folders(val_folder)\n",
    "\n",
    "test_path = \"./Data/data/test/\" # Augmented Data\n",
    "test_folder = os.listdir(test_path)\n",
    "remove_unwanted_folders(test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42569671-e5f2-4ff8-a340-0a9b6e49e7d2",
   "metadata": {},
   "source": [
    "### • Loading Images and creating Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7ca0cd-a454-4219-a823-28aaa05564cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "# Gathering Training Data\n",
    "for disease in train_folder:\n",
    "    images = os.listdir(os.path.join(train_path,disease))\n",
    "    for current_image in images:\n",
    "        # Load every image in current disease folder as cv2 image\n",
    "        current_image_full_path = os.path.join(train_path,disease,current_image)\n",
    "        current_image = cv2.imread(current_image_full_path)\n",
    "        current_image = cv2.resize(current_image,(224,224))\n",
    "        \n",
    "        train_x.append(current_image.flatten())\n",
    "        train_y.append(disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e13a42f5-2a9e-4a6d-b14b-d65a994a2e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "# Gathering Test Data\n",
    "for disease in test_folder:\n",
    "    images = os.listdir(os.path.join(test_path,disease))\n",
    "    for current_image in images:\n",
    "        # Load every image in current disease folder as cv2 image\n",
    "        current_image_full_path = os.path.join(test_path,disease,current_image)\n",
    "        current_image = cv2.imread(current_image_full_path)\n",
    "        current_image = cv2.resize(current_image,(224,224))\n",
    "        \n",
    "        test_x.append(current_image.flatten())\n",
    "        test_y.append(disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e3663-eded-4229-89b4-621117b882fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Val images to test array\n",
    "for disease in val_folder:\n",
    "    images = os.listdir(os.path.join(val_path,disease))\n",
    "    for current_image in images:\n",
    "        # Load every image in current disease folder as cv2 image\n",
    "        current_image_full_path = os.path.join(val_path,disease,current_image)\n",
    "        current_image = cv2.imread(current_image_full_path)\n",
    "        current_image = cv2.resize(current_image,(224,224))\n",
    "        \n",
    "        test_x.append(current_image.flatten())\n",
    "        test_y.append(disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96fb654a-88ac-4f6a-b16e-90d7b2ceb2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x Shape: (5675, 150528)\n",
      "Train_y Shape: (5675,)\n",
      "\n",
      "Test_x Shape: (810, 150528)\n",
      "Test_y Shape: (810,)\n"
     ]
    }
   ],
   "source": [
    "# Checking Shape of Training Data\n",
    "train_x = np.array(train_x).reshape(len(train_x), -1)/255\n",
    "train_y = np.array(train_y)\n",
    "print(f\"Train_x Shape: {train_x.shape}\\nTrain_y Shape: {train_y.shape}\\n\")\n",
    "\n",
    "\n",
    "# Checking Shape of Test Data\n",
    "test_x = np.array(test_x).reshape(len(test_x), -1)/255\n",
    "test_y = np.array(test_y)\n",
    "print(f\"Test_x Shape: {test_x.shape}\\nTest_y Shape: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3692937-6796-4438-912f-0bba4211e25b",
   "metadata": {},
   "source": [
    "### • Train Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9312049a-c414-41c3-a3d8-0b0a641a9bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel=\"rbf\")\n",
    "svc.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd25a37-7800-424d-882b-bb88aa6d440a",
   "metadata": {},
   "source": [
    "### • Generate Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3240ed-d8ce-411f-9599-c2b1f431bf24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_train = svc.predict(train_x)\n",
    "y_pred_test = svc.predict(test_x)\n",
    "print(\"Training accuracy:  \", accuracy_score(train_y,y_pred_train))\n",
    "print(\"Test accuracy:  \", accuracy_score(test_y,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589a510-7957-4048-ab7d-64e5ab7bb3c2",
   "metadata": {},
   "source": [
    "### • Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "dbad335b-e773-46d2-b762-2fc7e4461511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "            BA- cellulitis       0.91      0.94      0.92       170\n",
      "               BA-impetigo       0.93      0.69      0.79       100\n",
      "           FU-athlete-foot       0.97      0.96      0.96       156\n",
      "            FU-nail-fungus       0.83      0.89      0.86       162\n",
      "               FU-ringworm       0.82      0.73      0.77       113\n",
      "PA-cutaneous-larva-migrans       0.92      0.87      0.90       125\n",
      "             VI-chickenpox       0.97      0.96      0.96       170\n",
      "               VI-shingles       0.75      0.91      0.83       163\n",
      "\n",
      "                  accuracy                           0.88      1159\n",
      "                 macro avg       0.89      0.87      0.87      1159\n",
      "              weighted avg       0.89      0.88      0.88      1159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#y_pred = svc.predict(test_x)\n",
    "c_report = classification_report(test_y,y_pred)\n",
    "print(c_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d60a17-c685-4cc6-a3d4-ed60f0029139",
   "metadata": {},
   "source": [
    "### • Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47432d2-620e-4b66-8fc6-b48ca8aaa0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"./Saved_Models/svc_rbf.h5\"\n",
    "svc = pickle.load(open(model_name, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8597a14-b04b-445b-a610-b8ca626ec57e",
   "metadata": {},
   "source": [
    "### • Export model as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "666a5e72-cda9-49a6-b531-e9ec9de730cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_model =\"./Saved_Models/svc_rbf.h5\"\n",
    "pickle.dump(svc, open(save_model, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42303fc2-fd28-4999-a9b7-ff5a7b9abb90",
   "metadata": {},
   "source": [
    "### • Predict with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea6a030-683e-44b7-92fc-b092633b4c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load new image to predict\n",
    "img_path = './Data/data/val/VI-chickenpox/bH_145_VI-chickenpox (8).jpg'\n",
    "predict_image = cv2.imread(img_path)\n",
    "predict_image = cv2.resize(predict_image, (224,224))\n",
    "predict_image = np.array(predict_image.flatten()).reshape(1,-1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353fc193-0d5d-4d7e-a5ec-9be43e037bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc.predict(predict_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5a743-fe9d-48fe-b7fa-10285d08e8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "617c297d-3f47-40c8-870e-d121f3780fd5",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd9caf-2544-49c5-9fe0-f577e804e63f",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 4.1 Testing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dde5b3-e99e-4c2c-a3eb-30fcc7b6dd8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### • Test functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10d49a-f726-4ccc-ab12-e1338ba542b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07dfb5af-e1b9-4fac-aff8-df603eaf777a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### • Gather datapoints for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a986c95-eabb-4d40-991f-a51882b38bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edd76ac2-0116-48c9-87d4-dcf9e2370831",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 4.2 Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2eda8-3824-4c5a-b733-1cfb3d9f8c3a",
   "metadata": {},
   "source": [
    "### Visualizing with matplotlib:\n",
    "    • Test Loss\n",
    "    • Test Accuracy\n",
    "    • Visualise all model performances\n",
    "    • Visualise images with predicted area of infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10f801-0127-4d33-a159-7ab47d6fd14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dd68f5b-1c90-4c30-a899-541d16b48c93",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 4.3 Saving Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da88191-8fde-4f5d-b989-fda5a30e3f42",
   "metadata": {},
   "source": [
    "### Save predictions to \"predicted_data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841eee00-d989-4b50-bcbd-43bcbb4d8bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
